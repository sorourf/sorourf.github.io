<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sorour Fatemi | Visiting Assistant Professor at Cal State Monterey Bay</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <nav>
        <a href="index.html">Home</a>
        <a href="research.html">Research</a>
        <a href="teaching.html">Teaching</a>
        <a href="cv.html">CV</a>
        <a href="contact.html">Contact</a>
    </nav>

    <div class="container">
        <div class="profile-section">
            <div class="profile-image">
                <img src="profilepic.jpg" alt="Sorour Fatemi">
            </div>
            <div class="profile-content">
                <h1>Sorour Fatemi</h1>
                
                <p>I am a Visiting Assistant Professor at Cal State Monterey Bay.</p>
                
<p>My research advances large language models (LLMs) through the development of multi-agent frameworks that integrate diverse data modalities—text, visual charts, and numerical information—for complex reasoning tasks. These systems employ reflection mechanisms that enable agents to evaluate past decisions and refine their reasoning processes iteratively, with applications spanning financial text classification, market prediction, and question answering.</p>

<p>My ongoing work examines fundamental aspects of LLM decision-making under uncertainty. I investigate how multi-agent LLM architectures compare to traditional AutoML approaches on structured data classification, exploring their generalization capabilities and calibration properties. Additionally, I study whether LLMs exhibit human-like decision biases when learning from sequential feedback in risky environments. I am also developing judge-guided search methods that integrate immediate reasoning evaluation with long-term outcome estimation to enhance decision-making in domains characterized by delayed feedback.</p>

<p>In a separate line of research, I examine corporate disclosure practices surrounding artificial intelligence, developing LLM-based methodologies to detect misalignment between firms' AI-related claims and their actual investments, and analyzing the implications for information asymmetry and regulatory oversight.</p>

<p>You can find additional information about my work <a href="research.html">here</a>.</p>
            </div>
        </div>
    </div>
</body>
</html>
