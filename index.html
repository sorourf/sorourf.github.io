<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sorour Fatemi | Visiting Assistant Professor at Cal State Monterey Bay</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <nav>
        <a href="index.html">Home</a>
        <a href="research.html">Research</a>
        <a href="teaching.html">Teaching</a>
        <a href="cv.html">CV</a>
        <a href="contact.html">Contact</a>
    </nav>

    <div class="container">
        <div class="profile-section">
            <div class="profile-image">
                <img src="profilepic.jpg" alt="Sorour Fatemi">
            </div>
            <div class="profile-content">
                <h1>Sorour Fatemi</h1>
                
                <p>I am a Visiting Assistant Professor at Cal State Monterey Bay.</p>
                
<p>My research focuses on advancing the capabilities and understanding of large language models (LLMs) in financial and decision-making contexts. My published work examines how instruction fine-tuning can adapt smaller-scale LLMs for specialized financial text classification tasks, demonstrating that strategic model merging can preserve zero-shot performance while enhancing domain-specific accuracy. I have also developed multi-agent frameworks that leverage LLMs' ability to process multi-modal data—including textual reports, charts, and numerical information—for complex financial tasks such as stock market prediction and question answering, where reflection mechanisms enable agents to learn from past decisions and improve reasoning over time.</p>

<p>Building on these foundations, my current research investigates fundamental questions about how LLMs make decisions under uncertainty. I compare multi-agent LLM systems with traditional AutoML approaches on tabular classification tasks, exploring their generalization capabilities and calibration properties. Additionally, I examine whether LLMs develop human-like decision biases when learning from sequential feedback in risky environments, and I am developing judge-guided search methods that combine immediate reasoning evaluation with long-term outcome estimation for improved decision-making in domains with delayed feedback, such as trading, medical diagnosis, and strategic planning.</p>

<p>In parallel, I study corporate disclosure practices in the age of AI, developing LLM-based methods to detect "AI washing"—the misalignment between firms' AI-related claims and their actual AI investments—and examining its impact on information asymmetry and regulatory scrutiny.</p>

<p>You can find additional information about my work <a href="research.html">here</a>.</p>                
                <p>You can find additional information about my work <a href="research.html">here</a>.</p>
            </div>
        </div>
    </div>
</body>
</html>
