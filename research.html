<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research | Sorour Fatemi</title>
    <link rel="stylesheet" href="styles.css">
    <style>
        /* Collapsible Abstract Styling */
        .abstract-toggle {
            color: #0066cc;
            cursor: pointer;
            font-size: 16px;
            margin-top: 10px;
            display: inline-block;
            user-select: none;
        }
        
        .abstract-toggle:hover {
            text-decoration: underline;
        }
        
        .abstract-toggle::before {
            content: "▶ ";
            display: inline-block;
            transition: transform 0.2s;
            margin-right: 5px;
        }
        
        .abstract-toggle.active::before {
            transform: rotate(90deg);
        }
        
        .abstract-content {
            display: none;
            margin-top: 15px;
            padding-left: 20px;
            border-left: 3px solid #e0e0e0;
        }
        
        .abstract-content.show {
            display: block;
        }
    </style>
</head>
<body>
    <nav>
        <a href="index.html">Home</a>
        <a href="research.html">Research</a>
        <a href="teaching.html">Teaching</a>
        <a href="cv.html">CV</a>
        <a href="contact.html">Contact</a>
    </nav>

    <div class="container">
        <header>
            <h1>Research</h1>
        </header>

        <main>
            <section class="research-section">
                <h2 class="section-title">Published Papers</h2>
                
                <div class="research-project">
                    <h3>A Comparative Analysis of Instruction Fine-Tuning Large Language Models for Financial Text Classification</h3>
                    <p class="coauthors">With <a href="https://yuhenghu.com/" target="_blank">Yuheng Hu</a> (Fisher College of Business) and Maryam Mousavi</p>
                    <p class="publication"><em>ACM Transactions on Management Information Systems, Volume 16, Issue 1</em></p>
                    
                    <span class="abstract-toggle" onclick="toggleAbstract(this)">Abstract</span>
                    <div class="abstract-content">
                        <p>Large Language Models (LLMs) have demonstrated impressive capabilities across diverse Natural Language Processing (NLP) tasks, including language understanding, reasoning, and generation. However, general-domain LLMs often struggle with financial tasks due to the technical and specialized nature of financial texts. This study investigates the efficacy of instruction fine-tuning smaller-scale LLMs, including Mistral-7B, Llama3-8B, and Phi3-mini, to enhance their performance in financial text classification tasks. We fine-tuned both instruction-tuned and base models across four financial classification tasks, achieving significant improvements in task-specific performance. Furthermore, we evaluated the zero-shot capabilities of these fine-tuned models on three unseen complex financial tasks, including argument classification, deal completeness classification, and causal classification. Our results indicate while base model fine-tuning led to greater degradation, instruction-tuned models maintained more robust performance. To address this degradation, we employed model merging techniques, integrating single-task domain-specific fine-tuned models with the base model. Using this merging method resulted in significant enhancements in zero-shot performance, even exceeding the original model's accuracy on certain datasets. Our findings underscore the effectiveness of instruction fine-tuning and model merging for adapting LLMs to specialized financial text classification tasks.</p>
                    </div>
                </div>

                <div class="research-project">
                    <h3>FinVision: A Multi-Agent Framework for Stock Market Prediction</h3>
                    <p class="coauthors">With <a href="https://yuhenghu.com/" target="_blank">Yuheng Hu</a> (Fisher College of Business)</p>
                    <p class="publication"><em>ICAIF '24: Proceedings of the 5th ACM International Conference on AI in Finance</em></p>
                    
                    <span class="abstract-toggle" onclick="toggleAbstract(this)">Abstract</span>
                    <div class="abstract-content">
                        <p>Financial trading has been a challenging task, as it requires the integration of vast amounts of data from various modalities. Traditional deep learning and reinforcement learning methods require large training data and often involve encoding various data types into numerical formats for model input, which limits the explainability of model behavior. Recently, LLM-based agents have demonstrated remarkable advancements in handling multi-modal data, enabling them to execute complex, multi-step decision-making tasks while providing insights into their thought processes. This research introduces a multi-modal multi-agent system designed specifically for financial trading tasks. Our framework employs a team of specialized LLM-based agents, each adept at processing and interpreting various forms of financial data, such as textual news reports, candlestick charts, and trading signal charts. A key feature of our approach is the integration of a reflection module, which conducts analyses of historical trading signals and their outcomes. This reflective process is instrumental in enhancing the decision-making capabilities of the system for future trading scenarios. Furthermore, the ablation studies indicate that the visual reflection module plays a crucial role in enhancing the decision-making capabilities of our framework.</p>
                    </div>
                </div>

                <div class="research-project">
                    <h3>Enhancing Financial Question Answering with a Multi-Agent Reflection Framework</h3>
                    <p class="coauthors">With <a href="https://yuhenghu.com/" target="_blank">Yuheng Hu</a> (Fisher College of Business)</p>
                    
                    <span class="abstract-toggle" onclick="toggleAbstract(this)">Abstract</span>
                    <div class="abstract-content">
                        <p>While Large Language Models (LLMs) have shown impressive capabilities in numerous Natural Language Processing (NLP) tasks, they still struggle with financial question answering (QA), particularly when numerical reasoning is required. Recently, LLM-based multi-agent frameworks have demonstrated remarkable effectiveness in multi-step reasoning, which is crucial for financial QA tasks as it involves extracting relevant information from tables and text and then performing numerical reasoning on the extracted data to infer answers. In this study, we propose a multi-agent framework incorporating a critic agent that reflects on the reasoning steps and final answers for each question. Additionally, we enhance our system by adding multiple critic agents, each focusing on a specific aspect of the answer. Our results indicate that this framework significantly improves performance compared to single-agent reasoning, with an average performance increase of 15% for the LLaMA3-8B model and 5% for the LLaMA3-70B model. Furthermore, our framework performs on par with, and in some cases surpasses, larger single-agent LLMs such as LLaMA3.1-405B and GPT-4o-mini, though it falls slightly short compared to Claude-3.5 Sonnet. Overall, our framework presents an effective solution to enhance open-source LLMs for financial QA tasks, offering a cost-effective alternative to larger models like Claude-3.5 Sonnet.</p>
                    </div>
                </div>
            </section>

            <section class="research-section">
                <h2 class="section-title">Ongoing Research</h2>
                
                <div class="research-project">
                    <h3>Multi-Agent LLMs vs. AutoML for Tabular Classification</h3>
                    <p class="coauthors">With <a href="https://sites.google.com/view/aida-sanatizadeh" target="_blank">Aida Sanatizadeh</a> (Northern Illinois University), <a href="https://www.commerce.virginia.edu/faculty/rm6uz" target="_blank">Reza Mousavi</a> (University of Virginia McIntire School of Commerce), and <a href="https://ahmedabbasi.com/" target="_blank">Ahmed Abbasi</a> (University of Notre Dame)</p>
                    
                    <span class="abstract-toggle" onclick="toggleAbstract(this)">Abstract</span>
                    <div class="abstract-content">
                        <p>This project compares large language models (LLMs) with AutoML systems such as AutoGluon on structured data classification tasks. Using a modular multi-agent LLM (MALLM) framework, we tested performance across nine diverse datasets split by the LLMs' training cut-off date. We found that while MALLMs perform competitively on pre-cut-off datasets, their generalization drops on newer data, showing weaknesses in calibration and bias handling.</p>
                    </div>
                </div>

                <div class="research-project">
                    <h3>Learning from Experience or Learning from Outcomes? LLMs in Sequential Decision-Making Under Risk</h3>
                    <p class="coauthors">With <a href="https://sites.google.com/view/aida-sanatizadeh" target="_blank">Aida Sanatizadeh</a> (Northern Illinois University) and <a href="https://www.commerce.virginia.edu/faculty/rm6uz" target="_blank">Reza Mousavi</a> (University of Virginia McIntire School of Commerce)</p>
                    
                    <span class="abstract-toggle" onclick="toggleAbstract(this)">Abstract</span>
                    <div class="abstract-content">
                        <p>In order for AI systems to communicate effectively with people, they must understand how we make decisions. However, people's decisions are not always rational, so the implicit internal models of human decision-making in Large Language Models (LLMs) must account for this. Previous empirical evidence seems to suggest that these implicit models are accurate—LLMs offer believable proxies of human behavior, acting how we expect humans would in everyday interactions. This study explores whether LLMs develop human-like decision biases when learning from repeated feedback in risky choices. We run 30 LLM agents through 30 sequential gambling decisions (750 trials per agent), with and without outcome feedback. We aim to see if feedback leads LLMs to adopt human decision patterns or remain purely rational.</p>
                    </div>
                </div>

                <div class="research-project">
                    <h3>Judge-Guided Monte Carlo Tree Search for Stock Trading</h3>
                    <p class="coauthors">With <a href="https://yuhenghu.com/" target="_blank">Yuheng Hu</a> (Fisher College of Business)</p>
                    
                    <span class="abstract-toggle" onclick="toggleAbstract(this)">Abstract</span>
                    <div class="abstract-content">
                        <p>This work focuses on improving reasoning and decision-making under delayed feedback, such as in trading. Our Judge-Guided Monte Carlo Tree Search (JG-MCTS) setup combines immediate reasoning evaluation (by a "judge" LLM) with long-term outcome estimation through rollouts. The approach can generalize to domains like medical diagnosis, strategic planning, and policy modeling.</p>
                    </div>
                </div>

                <div class="research-project">
                    <h3>Measuring AI Washing: LLM-Based Detection and Market Consequences</h3>
                    
                    <span class="abstract-toggle" onclick="toggleAbstract(this)">Abstract</span>
                    <div class="abstract-content">
                        <p>As artificial intelligence becomes central to corporate strategy, firms face increasing pressure to demonstrate AI capabilities through disclosure. This study develops a novel measure of "AI washing"—the misalignment between firms' AI-related disclosure intensity and verifiable AI investments—using large language model (LLM) analysis of corporate communications. We address three primary research questions: (1) How can AI washing be systematically measured and validated? (2) Does AI washing increase information asymmetry between firms and investors? (3) Does AI washing predict regulatory scrutiny from the SEC?</p>
                    </div>
                </div>
            </section>
        </main>
    </div>

    <script>
        function toggleAbstract(element) {
            element.classList.toggle('active');
            const content = element.nextElementSibling;
            content.classList.toggle('show');
        }
    </script>
</body>
</html>
